{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMu92RgM9D65GNQ1V9eYkuI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9efa027b98d643f4b908cdcba399135b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_858b2de8c9814efc9cbd6a4a77506cd5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b759366ffd4f45d2ab977d308e6c0b93","IPY_MODEL_3753952147584f79ba424febc693d094"]}},"858b2de8c9814efc9cbd6a4a77506cd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b759366ffd4f45d2ab977d308e6c0b93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a28e9b07d7884703b08b6b39776e279d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef702f8b0b0d49079bb821b3a8b4942c"}},"3753952147584f79ba424febc693d094":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4e1793d32f4a4b999c5c36bc45e81fc7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 2.05MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff9b1cc818224e4b88c2698a84b08e77"}},"a28e9b07d7884703b08b6b39776e279d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef702f8b0b0d49079bb821b3a8b4942c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e1793d32f4a4b999c5c36bc45e81fc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff9b1cc818224e4b88c2698a84b08e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff0e3ffc295049a59c216ff06d9342b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c90cbadaea946caa4055bfe9ef66de3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_312bd4236a804c2b9f0945b8be5589b2","IPY_MODEL_6c49f990e2bd4a19b477d842b0807991"]}},"2c90cbadaea946caa4055bfe9ef66de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"312bd4236a804c2b9f0945b8be5589b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ff4e73ace21e4bde8120ba0f5bafabd6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e67fe2862914f28b4f339b0986a1ed8"}},"6c49f990e2bd4a19b477d842b0807991":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1599772dcd2542ef9d799879a4f6a178","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 1.08kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad51988bcc0948ee93fe55bfbdb8a5d9"}},"ff4e73ace21e4bde8120ba0f5bafabd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0e67fe2862914f28b4f339b0986a1ed8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1599772dcd2542ef9d799879a4f6a178":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad51988bcc0948ee93fe55bfbdb8a5d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9be3e47209149fc808fc56924599461":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f4c7a1e23ef4ac09b04a237dfef5bdf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2df95874e3e04aadab5f55dcead9b670","IPY_MODEL_79100113809b4e2f87fb975af3c5fa20"]}},"6f4c7a1e23ef4ac09b04a237dfef5bdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2df95874e3e04aadab5f55dcead9b670":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a91fab6d3424a77af1dba6459d68f5a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b998e4a97e964e0287881cb034e9beef"}},"79100113809b4e2f87fb975af3c5fa20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3c6dd0ff7bf841359a848d616f3a4bda","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436M/436M [00:07&lt;00:00, 56.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_beb5acf15cda4ca4ac02cef48b0c45e9"}},"2a91fab6d3424a77af1dba6459d68f5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b998e4a97e964e0287881cb034e9beef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c6dd0ff7bf841359a848d616f3a4bda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"beb5acf15cda4ca4ac02cef48b0c45e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61dcb1baef9a4a80a7946a34890ac183":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2bb227fc235443ba9ea0faad76d56244","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_60cd12babf284df7b1406a9cdc08aaa5","IPY_MODEL_f0df6b077b6c47ee963b2420a24996c6"]}},"2bb227fc235443ba9ea0faad76d56244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60cd12babf284df7b1406a9cdc08aaa5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d850a3a9ec3a4ebda2ca73cc1fc44886","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":46827520,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46827520,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2c84ad56a094c2b894ff06beb8b8a82"}},"f0df6b077b6c47ee963b2420a24996c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_862f34bd426243af935e661768a204b1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 44.7M/44.7M [00:08&lt;00:00, 5.73MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e062b23dd49640ff9af668d726a4ace3"}},"d850a3a9ec3a4ebda2ca73cc1fc44886":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f2c84ad56a094c2b894ff06beb8b8a82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"862f34bd426243af935e661768a204b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e062b23dd49640ff9af668d726a4ace3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZlGslsfmSZK","executionInfo":{"status":"ok","timestamp":1607336355453,"user_tz":-330,"elapsed":4390,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"049290d0-f25d-424b-8f13-1fe396b5b8a8"},"source":["# -*- coding: utf-8 -*_\n","\n","# NN library\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","# Bert model and its tokenizer\n","from transformers import BertTokenizer, BertModel\n","# Text data\n","from torchtext import data, datasets\n","# Numerical computation\n","import numpy as np\n","# standard library\n","import random\n","import time\n","# Configuration\n","#from config import *\n","\n","# Training configurations\n","SEED = 1234\n","TRAIN = False\n","BATCH_SIZE = 128\n","N_EPOCHS = 5\n","\n","# Architecture\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.25\n","\n","\n","# Set random seed for reproducible experiments\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","# Get tokens for BERT\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","init_token_id = tokenizer.cls_token_id\n","eos_token_id  = tokenizer.sep_token_id\n","pad_token_id  = tokenizer.pad_token_id\n","unk_token_id  = tokenizer.unk_token_id\n","\n","max_input_len = tokenizer.max_model_input_sizes['bert-base-uncased']\n","\n","# Tokensize and crop sentence to 510 (for 1st and last token) instead of 512 (i.e. `max_input_len`)\n","def tokenize_and_crop(sentence):\n","  tokens = tokenizer.tokenize(sentence)\n","  tokens = tokens[:max_input_len - 2]\n","  return tokens\n","\n","# Load the IMDB dataset and\n","# return (train_iter, valid_iter, test_iter) tuple\n","def load_data():\n","  text = data.Field(\n","    batch_first=True,\n","    use_vocab=False,\n","    tokenize=tokenize_and_crop,\n","    preprocessing=tokenizer.convert_tokens_to_ids,\n","    init_token=init_token_id,\n","    pad_token=pad_token_id,\n","    unk_token=unk_token_id\n","  )\n","\n","  label = data.LabelField(dtype=torch.float)\n","\n","  train_data, test_data  = datasets.IMDB.splits(text, label)\n","  train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n","\n","  print(f\"training examples count: {len(train_data)}\")\n","  print(f\"test examples count: {len(test_data)}\")\n","  print(f\"validation examples count: {len(valid_data)}\")\n","\n","  label.build_vocab(train_data)\n","\n","  train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=BATCH_SIZE,\n","    device=device\n","  )\n","\n","  return train_iter, valid_iter, test_iter\n","\n","# Get the device\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# \n","# Build model\n","# \n","\n","bert_model = BertModel.from_pretrained('bert-base-uncased')\n","#bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","\n","# Sentiment model containing pretrained BERT as backbone\n","# and two-GRU layers for analyzing the BERT hidden representation\n","# and a linear layer for classfification (the sigmoid is applied by the criterion during training).\n","import torch.nn as nn\n","\n","class SentimentModel(nn.Module):\n","  def __init__(\n","    self,\n","    bert,\n","    hidden_dim,\n","    output_dim,\n","    n_layers,\n","    bidirectional,\n","    dropout\n","  ):\n","      \n","    super(SentimentModel, self).__init__()\n","    \n","    self.bert = bert\n","    embedding_dim = bert.config.to_dict()['hidden_size']\n","    self.rnn = nn.GRU(\n","      embedding_dim,\n","      hidden_dim,\n","      num_layers=n_layers,\n","      bidirectional=bidirectional,\n","      batch_first=True,\n","      dropout=0 if n_layers < 2 else dropout\n","    )\n","    self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","    self.dropout = nn.Dropout(dropout)\n","      \n","  def forward(self, text):\n","    with torch.no_grad():\n","      embedded = self.bert(text)[0]\n","            \n","    _, hidden = self.rnn(embedded)\n","    \n","    if self.rnn.bidirectional:\n","      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","    else:\n","      hidden = self.dropout(hidden[-1,:,:])\n","    \n","    output = self.out(hidden)\n","    return output\n","\n","model = SentimentModel(\n","  bert_model,\n","  HIDDEN_DIM,\n","  OUTPUT_DIM,\n","  N_LAYERS,\n","  BIDIRECTIONAL,\n","  DROPOUT\n",")\n","print(model)\n","\n","\n","# function to make sentiment prediction during inference\n","def predict_sentiment(model, tokenizer, sentence):\n","  model.eval()\n","  tokens = tokenizer.tokenize(sentence)\n","  tokens = tokens[:max_input_len - 2]\n","  indexed = [init_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_id]\n","  tensor = torch.LongTensor(indexed).to(device)\n","  tensor = tensor.unsqueeze(0)\n","  prediction = torch.sigmoid(model(tensor))\n","  return prediction.item()\n","\n","#if __name__ == \"__main__\":\n","  # Infer from BERT"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SentimentModel(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (rnn): GRU(768, 256, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n","  (out): Linear(in_features=512, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.25, inplace=False)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"51liJL2ipOYy"},"source":["#!pip install transformers\n","#The output closer to 1 means hate speech whereas in case of close to 0 means the content of text is good/happy."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zr-UlkKxpr8o","executionInfo":{"status":"ok","timestamp":1607336408885,"user_tz":-330,"elapsed":1227,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"c94a92c6-4881-4f7f-bb1a-85dbf8dd8ac8"},"source":["  TEXT = \"good\"\n","  sentiment = predict_sentiment(model, tokenizer, TEXT)\n","  print(sentiment)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.49479570984840393\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AF67Q07sCXnQ","executionInfo":{"status":"ok","timestamp":1607408939117,"user_tz":-330,"elapsed":22843,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"ae752fb7-48d9-4668-ced6-3c3e0668f1bf"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-lUeiDMMqJTE"},"source":["#!kaggle competitions download -c twitter-sentiment-analysis\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWT5XNo3yd_C","executionInfo":{"status":"ok","timestamp":1607408944665,"user_tz":-330,"elapsed":1138,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"f886474d-48e8-4bad-fb18-bb7cbb788cf7"},"source":["%cd '/content/gdrive/MyDrive/BERT'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/BERT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wH1R2H2Pw_Gb"},"source":["\n","##import os\n","#import urllib.request\n","#urllib.request.urlretrieve(\"https://drive.google.com/u/1/uc?export=download&confirm=akgp&id=1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\",\"new.bin\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b5TgRteC9-O"},"source":["#!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYNigw3QyAWp"},"source":["import json\n","\n","from torch import nn\n","from transformers import BertModel\n","\n","\n","with open(\"config.json\") as json_file:\n","    config = json.load(json_file)\n","\n","\n","class SentimentClassifier(nn.Module):\n","    def __init__(self, n_classes):\n","        super(SentimentClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained(config[\"BERT_MODEL\"])\n","        self.drop = nn.Dropout(p=0.3)\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        output = self.drop(pooled_output)\n","        return self.out(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":806,"referenced_widgets":["9efa027b98d643f4b908cdcba399135b","858b2de8c9814efc9cbd6a4a77506cd5","b759366ffd4f45d2ab977d308e6c0b93","3753952147584f79ba424febc693d094","a28e9b07d7884703b08b6b39776e279d","ef702f8b0b0d49079bb821b3a8b4942c","4e1793d32f4a4b999c5c36bc45e81fc7","ff9b1cc818224e4b88c2698a84b08e77","ff0e3ffc295049a59c216ff06d9342b0","2c90cbadaea946caa4055bfe9ef66de3","312bd4236a804c2b9f0945b8be5589b2","6c49f990e2bd4a19b477d842b0807991","ff4e73ace21e4bde8120ba0f5bafabd6","0e67fe2862914f28b4f339b0986a1ed8","1599772dcd2542ef9d799879a4f6a178","ad51988bcc0948ee93fe55bfbdb8a5d9","a9be3e47209149fc808fc56924599461","6f4c7a1e23ef4ac09b04a237dfef5bdf","2df95874e3e04aadab5f55dcead9b670","79100113809b4e2f87fb975af3c5fa20","2a91fab6d3424a77af1dba6459d68f5a","b998e4a97e964e0287881cb034e9beef","3c6dd0ff7bf841359a848d616f3a4bda","beb5acf15cda4ca4ac02cef48b0c45e9"]},"id":"-rHrN5pY4kRL","executionInfo":{"status":"error","timestamp":1607409151901,"user_tz":-330,"elapsed":12808,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"e517da37-8f0e-48cf-fe18-8151b29f6969"},"source":["#import json\n","\n","import torch\n","import torch.nn.functional as F\n","from transformers import BertTokenizer\n","\n","#from .sentiment_classifier import SentimentClassifier\n","\n","#with open(\"config.json\") as json_file:\n","#   config = json.load(json_file)\n","\n","\n","class Model:\n","    def __init__(self):\n","\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","        self.tokenizer = BertTokenizer.from_pretrained(config[\"BERT_MODEL\"])\n","\n","        classifier = SentimentClassifier(len(config[\"CLASS_NAMES\"]))\n","        classifier.load_state_dict(\n","            torch.load(config[\"PRE_TRAINED_MODEL\"], map_location=self.device)\n","        )\n","        classifier = classifier.eval()\n","        self.classifier = classifier.to(self.device)\n","\n","    def predict(self, text):\n","        encoded_text = self.tokenizer.encode_plus(\n","            text,\n","            max_length=config[\"MAX_SEQUENCE_LEN\"],\n","            add_special_tokens=True,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors=\"pt\",\n","        )\n","        input_ids = encoded_text[\"input_ids\"].to(self.device)\n","        attention_mask = encoded_text[\"attention_mask\"].to(self.device)\n","\n","        with torch.no_grad():\n","            probabilities = F.softmax(self.classifier(input_ids, attention_mask), dim=1)\n","        confidence, predicted_class = torch.max(probabilities, dim=1)\n","        predicted_class = predicted_class.cpu().item()\n","        probabilities = probabilities.flatten().cpu().numpy().tolist()\n","        return (\n","            config[\"CLASS_NAMES\"][predicted_class],\n","            confidence,\n","            dict(zip(config[\"CLASS_NAMES\"], probabilities)),\n","        )\n","\n","\n","model = Model()\n","\n","\n","def get_model():\n","    return model"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9efa027b98d643f4b908cdcba399135b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff0e3ffc295049a59c216ff06d9342b0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9be3e47209149fc808fc56924599461","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"error","ename":"UnpicklingError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-3618d5f97ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-3618d5f97ec5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CLASS_NAMES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         classifier.load_state_dict(\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PRE_TRAINED_MODEL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \"functionality.\")\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."]}]},{"cell_type":"code","metadata":{"id":"xqksbjlT41aH"},"source":["from typing import Dict\n","\n","from fastapi import Depends, FastAPI\n","from pydantic import BaseModel\n","\n","from .classifier.model import Model, get_model\n","\n","app = FastAPI()\n","\n","\n","class SentimentRequest(BaseModel):\n","    text: str\n","\n","\n","class SentimentResponse(BaseModel):\n","    probabilities: Dict[str, float]\n","    sentiment: str\n","    confidence: float\n","\n","\n","@app.post(\"/predict\", response_model=SentimentResponse)\n","def predict(request: SentimentRequest, model: Model = Depends(get_model)):\n","    sentiment, confidence, probabilities = model.predict(request.text)\n","    return SentimentResponse(\n","        sentiment=sentiment, confidence=confidence, probabilities=probabilities\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOwZ7HpVB8MW"},"source":["##### IMAGE SIMILARITY"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQdPEBiPrV8n"},"source":["# IMAGE SIMILARITY"]},{"cell_type":"code","metadata":{"id":"A2z9zV-fB8SB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607419875752,"user_tz":-330,"elapsed":177105,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"b3d9f12e-1cfa-4b4c-d907-b2fbbb5a7dc9"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdQu8GY33RyZ"},"source":["%cd '/content/gdrive/MyDrive/BERT/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFPw1R_nB8VZ","executionInfo":{"status":"ok","timestamp":1607419879533,"user_tz":-330,"elapsed":5660,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["import torch\n","import torch.nn as nn\n","#import torchvision\n","#import torchvision.transforms as transforms\n","import os\n","import cv2\n","import numpy as np\n","import sklearn\n","from sklearn import preprocessing"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0OPTXLcCG2V","executionInfo":{"status":"ok","timestamp":1607419879534,"user_tz":-330,"elapsed":5352,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["#using Pretrained model\n","import torchvision\n","from torchvision import models\n","from torchvision import transforms\n","#from PIL import Image\n","from PIL import Image, ExifTags\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["61dcb1baef9a4a80a7946a34890ac183","2bb227fc235443ba9ea0faad76d56244","60cd12babf284df7b1406a9cdc08aaa5","f0df6b077b6c47ee963b2420a24996c6","d850a3a9ec3a4ebda2ca73cc1fc44886","f2c84ad56a094c2b894ff06beb8b8a82","862f34bd426243af935e661768a204b1","e062b23dd49640ff9af668d726a4ace3"]},"id":"Gn9rHIf4CAZ8","executionInfo":{"status":"ok","timestamp":1607420428996,"user_tz":-330,"elapsed":2403,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"3b86589a-ad38-416c-c1a6-e16e4a8cfe85"},"source":["#using Pretrained model\n","model = models.resnet18(pretrained = True,)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61dcb1baef9a4a80a7946a34890ac183","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X5_xY8-VDIVW","executionInfo":{"status":"ok","timestamp":1607420431708,"user_tz":-330,"elapsed":1553,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["newmodel = torch.nn.Sequential(*(list(model.children())[:-1]))\n","#print(newmodel)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZBthuLexICu","executionInfo":{"status":"ok","timestamp":1607421789081,"user_tz":-330,"elapsed":1582,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":[""],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYYCVa4VxGOc","executionInfo":{"status":"ok","timestamp":1607421367671,"user_tz":-330,"elapsed":1326,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["def fix_orientation(image):\n","    \"\"\" Look in the EXIF headers to see if this image should be rotated. \"\"\"\n","    try:\n","        for orientation in ExifTags.TAGS.keys():\n","            if ExifTags.TAGS[orientation] == \"Orientation\":\n","                break\n","        exif = dict(image._getexif().items())\n","\n","        if exif[orientation] == 3:\n","            image = image.rotate(180, expand=True)\n","        elif exif[orientation] == 6:\n","            image = image.rotate(270, expand=True)\n","        elif exif[orientation] == 8:\n","            image = image.rotate(90, expand=True)\n","        return image\n","    except (AttributeError, KeyError, IndexError):\n","        return image\n","\n","\n","def extract_center(image):\n","    \"\"\" Most of the models need a small square image. Extract it from the center of our image.\"\"\"\n","    width, height = image.size\n","    new_width = new_height = min(width, height)\n","\n","    left = (width - new_width) / 2\n","    top = (height - new_height) / 2\n","    right = (width + new_width) / 2\n","    bottom = (height + new_height) / 2\n","\n","    return image.crop((left, top, right, bottom))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2pW02t9x5Xu","executionInfo":{"status":"ok","timestamp":1607422597065,"user_tz":-330,"elapsed":1376,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["\n","def final(image_path):\n","  image_size = 224\n","  #print_interval = len(file_names) / 10\n","  im = Image.open(image_path)\n","  im = fix_orientation(im)\n","  im = extract_center(im)\n","  im = im.resize((image_size, image_size))\n","  im = im.convert(mode=\"RGB\")\n","  image_data= np.array(im)\n","  data_transform = transforms.ToTensor()\n","  image_data = data_transform(image_data)\n","  image_data = newmodel(image_data.unsqueeze(0))\n","  image_data = np.array(image_data.detach().numpy()[0]) \n","  return image_data"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ih7YnGTdETnl"},"source":["'''\n","file2 = Image.open('/content/gdrive/MyDrive/all_souls_000026.jpg')\n","img2 = data_transform(file2)\n","op2 = newmodel(img2.unsqueeze(0))\n","B = np.array(op2.detach().cpu().numpy()[0]) \n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYEqXkD6ExuG","executionInfo":{"status":"ok","timestamp":1607423395961,"user_tz":-330,"elapsed":2286,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["A=final('/content/gdrive/MyDrive/BERT/new1000x650.jpg')\n","B=final('/content/gdrive/MyDrive/BERT/1000x650-78.jpg')"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRwtN2MPOZMu","executionInfo":{"status":"ok","timestamp":1607423491755,"user_tz":-330,"elapsed":1241,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"f74b2dd3-5e38-4c24-ed5b-f4902fc69642"},"source":["# using sklearn to calculate cosine similarity\n","from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n","cos_sim=cosine_similarity(A.reshape(1,-1),B.reshape(1,-1))\n","print (f\"Cosine Similarity between A and B:{cos_sim}\")\n","print (f\"Cosine Distance between A and B:{1-cos_sim}\")"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Cosine Similarity between A and B:[[0.99830127]]\n","Cosine Distance between A and B:[[0.00169873]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EVRZewt-wQXB","executionInfo":{"status":"ok","timestamp":1607423401471,"user_tz":-330,"elapsed":776,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["counter=0\n","for i in A.reshape(1,-1)[0]:\n","  if i in B.reshape(1,-1)[0]:\n","    counter=counter+1"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fq2gMWEp5A7u","executionInfo":{"status":"ok","timestamp":1607423403936,"user_tz":-330,"elapsed":1161,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"84f481bd-d0f2-4af5-d77c-63a60a0e8fb5"},"source":["counter"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"w5ifpIkjBpw7"},"source":["#"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvAbOgezBtag"},"source":["# BERT: TEXT MODERN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SGH7YeSNBn9D","executionInfo":{"status":"ok","timestamp":1607425541707,"user_tz":-330,"elapsed":8181,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"5621e82e-1a9b-4cd9-e4f9-e9ba37760e18"},"source":["!pip install transformers"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 14.6MB/s \n","\u001b[?25hCollecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 20.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=30a376c20eb74325e6b1c4448a0360ac20a4597986a10d125bd7a4d1c8b88fd4\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh2kWJASEzlO","executionInfo":{"status":"ok","timestamp":1607426332588,"user_tz":-330,"elapsed":3213,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"b151ff43-02dc-499f-857c-19d816690d7e"},"source":["%cd '/content/gdrive/MyDrive/TEXT_MODERN'"],"execution_count":91,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/TEXT_MODERN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pI_NnMwME1W_","executionInfo":{"status":"ok","timestamp":1607426363360,"user_tz":-330,"elapsed":14363,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"eb50a156-f883-4908-c36e-8bb9b07f74dd"},"source":["#!unzip '/content/gdrive/MyDrive/TEXT_MODERN/jigsaw-toxic-comment-classification-challenge.zip'"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Archive:  /content/gdrive/MyDrive/TEXT_MODERN/jigsaw-toxic-comment-classification-challenge.zip\n","  inflating: sample_submission.csv.zip  \n","  inflating: test.csv.zip            \n","  inflating: test_labels.csv.zip     \n","  inflating: train.csv.zip           \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26IWZVR9E1g5","executionInfo":{"status":"ok","timestamp":1607426435013,"user_tz":-330,"elapsed":3916,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"c0dce6f5-dcdb-4270-cb8c-2bd69cf2a53a"},"source":["#!unzip '/content/gdrive/MyDrive/TEXT_MODERN/sample_submission.csv.zip'\n","#!unzip '/content/gdrive/MyDrive/TEXT_MODERN/test.csv.zip'\n","#!unzip '/content/gdrive/MyDrive/TEXT_MODERN/test_labels.csv.zip'\n","#!unzip '/content/gdrive/MyDrive/TEXT_MODERN/train.csv.zip'"],"execution_count":93,"outputs":[{"output_type":"stream","text":["Archive:  /content/gdrive/MyDrive/TEXT_MODERN/sample_submission.csv.zip\n","  inflating: sample_submission.csv   \n","Archive:  /content/gdrive/MyDrive/TEXT_MODERN/test.csv.zip\n","  inflating: test.csv                \n","Archive:  /content/gdrive/MyDrive/TEXT_MODERN/test_labels.csv.zip\n","  inflating: test_labels.csv         \n","Archive:  /content/gdrive/MyDrive/TEXT_MODERN/train.csv.zip\n","  inflating: train.csv               \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FrHNmrX05MnQ","executionInfo":{"status":"ok","timestamp":1607425544499,"user_tz":-330,"elapsed":8464,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["import torch\n","import pickle\n","from torch import nn\n","import numpy as np\n","import pandas as pd\n","from transformers import *\n","from sklearn.metrics import roc_curve, auc\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, DataLoader, random_split"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9QLIMqcBifY","executionInfo":{"status":"ok","timestamp":1607425544500,"user_tz":-330,"elapsed":3638,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["class InputExample(object):\n","    def __init__(self, id, text, labels=None):\n","        self.id = id\n","        self.text = text\n","        self.labels = labels\n","\n","class InputFeatures(object):\n","    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_ids = label_ids"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1fBuvTfB0Kw","executionInfo":{"status":"ok","timestamp":1607425574108,"user_tz":-330,"elapsed":1487,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["\n","def get_train_examples(train_file):\n","    train_df = pd.read_csv(train_file)\n","    ids = train_df['id'].values\n","    text = train_df['comment_text'].values\n","    labels = train_df[train_df.columns[2:]].values\n","    examples = []\n","    for i in range(len(train_df)):\n","        examples.append(InputExample(ids[i], text[i], labels=labels[i]))\n","    return examples"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"id":"WReH75hGB77B","executionInfo":{"status":"ok","timestamp":1607425581581,"user_tz":-330,"elapsed":1494,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["def get_features_from_examples(examples, max_seq_len, tokenizer):\n","    features = []\n","    for i,example in enumerate(examples):\n","        tokens = tokenizer.tokenize(example.text)\n","        if len(tokens) > max_seq_len - 2:\n","            tokens = tokens[:(max_seq_len - 2)]\n","        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","        input_mask = [1] * len(input_ids)\n","        segment_ids = [0] * len(tokens)\n","        padding = [0] * (max_seq_len - len(input_ids))\n","        input_ids += padding\n","        input_mask += padding\n","        segment_ids += padding\n","        assert len(input_ids) == max_seq_len\n","        assert len(input_mask) == max_seq_len\n","        assert len(segment_ids) == max_seq_len\n","        label_ids = [float(label) for label in example.labels]\n","        features.append(InputFeatures(input_ids=input_ids,\n","                                      input_mask=input_mask,\n","                                      segment_ids=segment_ids,\n","                                      label_ids=label_ids))\n","    return features"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwvoe5UYB9v6","executionInfo":{"status":"ok","timestamp":1607425601854,"user_tz":-330,"elapsed":1166,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["def get_dataset_from_features(features):\n","    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","    segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","    label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.float)\n","    dataset = TensorDataset(input_ids,\n","                            input_mask,\n","                            segment_ids,\n","                            label_ids)\n","    return dataset"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIr1Ot2bCCxs","executionInfo":{"status":"ok","timestamp":1607425617965,"user_tz":-330,"elapsed":1344,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["class KimCNN(nn.Module):\n","    def __init__(self, embed_num, embed_dim, dropout=0.1, kernel_num=3, kernel_sizes=[2,3,4], num_labels=2):\n","        super().__init__()\n","        self.num_labels = num_labels\n","        self.embed_num = embed_num\n","        self.embed_dim = embed_dim\n","        self.dropout = dropout\n","        self.kernel_num = kernel_num\n","        self.kernel_sizes = kernel_sizes\n","        self.embed = nn.Embedding(self.embed_num, self.embed_dim)\n","        self.convs = nn.ModuleList([nn.Conv2d(1, self.kernel_num, (k, self.embed_dim)) for k in self.kernel_sizes])\n","        self.dropout = nn.Dropout(self.dropout)\n","        self.classifier = nn.Linear(len(self.kernel_sizes)*self.kernel_num, self.num_labels)\n","        \n","    def forward(self, inputs, labels=None):\n","        output = inputs.unsqueeze(1)\n","        output = [nn.functional.relu(conv(output)).squeeze(3) for conv in self.convs]\n","        output = [nn.functional.max_pool1d(i, i.size(2)).squeeze(2) for i in output]\n","        output = torch.cat(output, 1)\n","        output = self.dropout(output)\n","        logits = self.classifier(output)\n","        if labels is not None:\n","            loss_fct = nn.BCEWithLogitsLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n","            return loss\n","        else:\n","            return logits"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"6OIRgqzPCGqy","executionInfo":{"status":"ok","timestamp":1607425651562,"user_tz":-330,"elapsed":4294,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["device = torch.device(type='cuda')\n","pretrained_weights = 'bert-base-cased'\n","tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n","basemodel = BertModel.from_pretrained(pretrained_weights)\n","#basemodel.to(device)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvGqb3r4CPnh","executionInfo":{"status":"ok","timestamp":1607426652686,"user_tz":-330,"elapsed":206541,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["seq_len = 256\n","train_file = 'train.csv'\n","train_examples = get_train_examples(train_file)\n","train_features = get_features_from_examples(train_examples, seq_len, tokenizer)\n","train_dataset = get_dataset_from_features(train_features)\n","\n","\n","train_val_split = 0.1\n","train_size = int(len(train_dataset)*(1-train_val_split))\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","batch = 8\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch)\n","val_sampler = SequentialSampler(val_dataset)\n","val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch)"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"mip2ifSECIws"},"source":["embed_num = seq_len \n","embed_dim = basemodel.config.hidden_size \n","dropout = basemodel.config.hidden_dropout_prob\n","kernel_num = 3\n","kernel_sizes = [2,3,4]\n","num_labels = 6\n","\n","model = KimCNN(embed_num, embed_dim, dropout=dropout, kernel_num=kernel_num, kernel_sizes=kernel_sizes, num_labels=num_labels)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0b2tx5RGD78"},"source":["lr = 3e-5\n","epochs = 1\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","\n","for i in range(epochs):\n","    print('-----------EPOCH #{}-----------'.format(i+1))\n","    print('training...')\n","    model.train()\n","    for step, batch in enumerate(train_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_ids = batch\n","        with torch.no_grad():\n","            inputs,_ = basemodel(input_ids, segment_ids, input_mask)\n","        loss = model(inputs, label_ids)\n","        loss = loss.mean()\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()        \n","    \n","    y_true = []\n","    y_pred = []\n","\n","    model.eval()\n","    print('evaluating...')\n","    for step, batch in enumerate(val_dataloader):\n","        batch = tuple(t.to(device) for t in batch)\n","        val_input_ids, val_input_mask, val_segment_ids, val_label_ids = batch\n","        with torch.no_grad():\n","            val_inputs,_ = basemodel(val_input_ids, val_segment_ids, val_input_mask)\n","            logits = model(val_inputs)\n","        y_true.append(val_label_ids)\n","        y_pred.append(logits)\n","\n","    y_true = torch.cat(y_true, dim=0).float().cpu().detach().numpy()\n","    y_pred = torch.cat(y_pred, dim=0).float().cpu().detach().numpy()\n","\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","\n","    for i,label in enumerate(labels):\n","        fpr[label], tpr[label], _ = roc_curve(y_true[:, i], y_pred[:, i])\n","        roc_auc[label] = auc(fpr[label], tpr[label])\n","\n","    print('ROC AUC per label:')\n","    for label in labels:\n","        print(label, ': ', roc_auc[label])\n"],"execution_count":null,"outputs":[]}]}