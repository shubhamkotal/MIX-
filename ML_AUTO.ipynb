{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"ML_AUTO.ipynb","provenance":[{"file_id":"1xO-oxGJuJj3KeLu89hTWpSwx1mxLMIyE","timestamp":1617777712245}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujmq_TyV1qPw","executionInfo":{"status":"ok","timestamp":1618387785792,"user_tz":-330,"elapsed":29198,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"1e3eee5f-8d56-4182-a62a-978c844f0038"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bG4tlfrR1-Tj","executionInfo":{"status":"ok","timestamp":1618230886954,"user_tz":-330,"elapsed":1376,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"f39c1c45-9c89-4954-fd8a-daefc2d57497"},"source":["%cd '/content/gdrive/MyDrive/ML_automation/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: '/content/gdrive/MyDrive/ML_automation/'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"27kRvomrYB_O","executionInfo":{"status":"ok","timestamp":1619751022119,"user_tz":-330,"elapsed":1414,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}}},"source":["from sklearn import datasets\n","import pandas as pd\n","iris = datasets.load_iris()\n","df=pd.DataFrame(iris['data'])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"5APtrURSfmkp","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"ok","timestamp":1619751029171,"user_tz":-330,"elapsed":1144,"user":{"displayName":"Shubham Kotal","photoUrl":"","userId":"17346389805356489008"}},"outputId":"09d7db8a-d87a-4ac2-fa06-4b0ca49aaf90"},"source":["df.to"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["       0    1    2    3\n","0    5.1  3.5  1.4  0.2\n","1    4.9  3.0  1.4  0.2\n","2    4.7  3.2  1.3  0.2\n","3    4.6  3.1  1.5  0.2\n","4    5.0  3.6  1.4  0.2\n","..   ...  ...  ...  ...\n","145  6.7  3.0  5.2  2.3\n","146  6.3  2.5  5.0  1.9\n","147  6.5  3.0  5.2  2.0\n","148  6.2  3.4  5.4  2.3\n","149  5.9  3.0  5.1  1.8\n","\n","[150 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"R4FmkTGWFLlu"},"source":["import sqlite3\n","import os\n","import pickle\n","import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings \n","import numpy\n","warnings.filterwarnings('ignore')\n","from sklearn import preprocessing\n","from sklearn.preprocessing import StandardScaler\n","from mlxtend.preprocessing import minmax_scaling\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn import metrics\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import svm\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn import neighbors\n","import math\n","import xgboost as xg\n","from sklearn.svm import SVR\n","\n","# 1. LOADING\n","\n","# 1.1\n","def read_data_from_db(sqlite3_query,cur_execute_query,table_query):\n","  '''\n","    Read data from database and pull to console as DataFrame\n","\n","    Input Parameters: \n","                    a. sqlite3_query\n","                    b. cur_execute_query\n","                    c. table_query\n","                \n","    Returns: DataFrame\n","  '''\n","  # Create a SQL connection to our SQLite database\n","  con = sqlite3.connect(sqlite3_query)\n","  cur = con.cursor()\n","  # Be sure to close the connection\n","  cur.execute(cur_execute_query)\n","  print(cur.fetchall())\n","  df = pd.read_sql_query(table_query, con) \n","  cur.close()\n","  con.close()\n","  return df\n","\n","# 1.2\n","\n","def read_data(csv_file_path):\n","  '''\n","    Read CSV file \n","\n","    Input Parameters: File Path (.csv)\n","                \n","    Returns: DataFrame\n","  '''\n","  df = pd.read_csv(csv_file_path)\n","  return df\n","\n","# 2. PREPROCESSING\n","\n","# 2.1\n","\n","def data_type_correction(df):\n","  ''' \n","    Performs auto correction of data type of each column \n","  \n","    Input Parameters: DataFrame\n","                \n","    Returns: DataFrame\n","  '''\n","  num_values=df.select_dtypes(['float64','int64','int16','float16','float64','int64']).columns\n","  cat_values=[i for i in df.columns if i not in num_values]\n","  df[cat_values]=df[cat_values].astype('str')\n","  return df\n","\n","# 2.2\n","def auto_remove_unwanted_columns(df):\n","  ''' \n","    Performs auto removal of columns which are not useful for model training \n","  \n","    Input Parameters: DataFrame\n","                \n","    Returns: DataFrame\n","  '''\n","  num_values=df.select_dtypes(['float64','int64','int16','float16','float64','int64']).columns\n","  cat_values=[i for i in df.columns if i not in num_values]\n","  for i in cat_values:\n","    if int(df[i].value_counts()) == 1 or int(df[i].value_counts()) == len(df[i]):\n","      df=df.drop(i,axis=1)\n","  return df\n","\n","# 2.3\n","def auto_imputer(df):\n","  ''' \n","    Imputation of empty enteries by central tendency: Mean and Mode  \n","  \n","    Input Parameters: DataFrame\n","                \n","    Returns: DataFrame\n","  '''\n","  num_values=df.select_dtypes(['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns\n","  cat_values=[i for i in df.columns if i not in num_values]\n","  for column in cat_values:\n","    df[column].fillna((df[column].mode()), inplace=True)\n","  for column in num_values:\n","    df[column].fillna((df[column].mean()), inplace=True)\n","  return df\n","\n","# 2.4\n","def remove_correlated_columns(df,threshold):\n","  ''' \n","    Auto Removal of hight co-related columns based on user threshold. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Threshold: numeric attribute\n","                    \n","    Returns: DataFrame\n","  '''\n","  # Create correlation matrix\n","  corr_matrix = df.corr().abs()\n","  # Select upper triangle of correlation matrix\n","  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n","  # Find features with correlation greater than threshold\n","  to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n","  # Drop features \n","  df.drop(to_drop, axis=1, inplace=True)\n","  return df\n","\n","# 2.5\n","def target_label_encoder(df,target_variable,encoding_type): \n","  ''' \n","    Encodes categorical attributes to numerical attributes\n","    Input Parameters: \n","                     a. DataFrame\n","                     b. Target Variable: 'target_variable'\n","                     c. Encoding Type : 'label' , 'onehot' \n","                \n","    Returns: DataFrame\n","  '''\n","  le = preprocessing.LabelEncoder()\n","  target=df[target_variable]\n","  df=df.drop(target_variable,axis=1)\n","  num_values=df.select_dtypes(['float64','int64','int16','float16','float64','int64']).columns \n","  cat_values=[i for i in df.columns if i not in num_values]\n","  for column in cat_values:\n","    if encoding_type=='label':        \n","      le.fit(list(df[column]))\n","      df[column]=le.transform(list(df[column]))\n","    elif encoding_type=='onehot':\n","      dummies = pd.get_dummies(df[column], prefix=column, drop_first=False)\n","      df = pd.concat([df, dummies], axis=1)\n","      df=df.drop([column],axis=1)\n","  df[target_variable]=target\n","  return df\n","\n","# 2.6\n","def standard_scale(df,target_variable):\n","  ''' \n","    Normalization of numeric type columns based on standard scaler method.\n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    \n","    Returns: DataFrame\n","  '''\n","  num_values=df.select_dtypes(['float64','int64','int16','float16','float64','int64']).columns\n","  try:\n","    num_values=num_values.drop(target_variable)\n","  except:\n","    pass\n","  scaler = StandardScaler()\n","  scaler.fit(df[num_values])\n","  df[num_values]=scaler.transform(df[num_values])\n","  return df\n","\n","#2.7\n","def minmax_scale(df,target_variable):\n","  ''' \n","    Normalization of numeric type columns based on min-max scaler method.\n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    \n","    Returns: DataFrame\n","  '''\n","  num_values=df.select_dtypes(['float64','int64','int16','float16','float64','int64']).columns\n","  try:\n","    num_values=num_values.drop(target_variable)\n","  except:\n","    pass\n","  scaled_data1 = minmax_scaling(df,columns=num_values)\n","  for column in num_values:\n","    df[column] = scaled_data1[column]\n","  return df\n","\n","#3. FUNCTION USED IN MODELLING \n","# NEEDED \n","def train_and_test_split(df,target_variable):\n","  ''' \n","    Splitting Data to two sets: Train and Test\n","\n","    Input Parameters: \n","                     a. DataFrame\n","                     b. Target Variable: 'target_variable'\n","                    \n","    Returns: train dataset, test dataset, train target, test target\n","  '''\n","  columns = list(df.columns)\n","  columns.remove(target_variable)\n","  X = df[columns]\n","  Y = df[target_variable]\n","  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=1)\n","  return X_train, X_test, y_train, y_test\n","\n","\n","#4. CLASSIFICATION MODELLING\n","\n","# 4.1\n","\n","# def logistic_regression_model(df,target_variable,output_file_name):\n","#   ''' \n","#     Create and train machine learning model for prediction of independent variable\n","#     based on dependent variables in the dataframe. \n","#     Input Parameters: \n","#                     a. DataFrame\n","#                     b. Target Variable: 'target_variable'\n","#                     c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","#     Returns: \n","#            Display Results:\n","#                    a. Confusion Matrix\n","#                    b. Classification Report\n","#                    c. Accuracy\n","#   '''\n","#   X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","#   if len(set(y_train)) == 2:\n","#     model = LogisticRegression(solver='liblinear', random_state=0)\n","#   else:\n","#     model = LogisticRegression(multi_class = 'multinomial', random_state=0)\n","#   model=model.fit(X_train,y_train)\n","#   test_pred=model.predict(X_test)\n","#   confusion_matrix_result=confusion_matrix(y_test,test_pred)\n","#   classification_report_result=classification_report(y_test,test_pred)\n","#   accuracy_score= metrics.accuracy_score(y_test,test_pred)* 100 \n","#   if output_file_name != None:\n","#     pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","#     print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","\n","#   return confusion_matrix_result,classification_report_result,accuracy_score\n","\n","# 4.2\n","def Support_Vector_classifier(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","\n","                    \n","    Returns: \n","           Display Results:\n","                   a. Confusion Matrix\n","                   b. Classification Report\n","                   c. Accuracy\n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = svm.SVC()\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  confusion_matrix_result=confusion_matrix(y_test,test_pred)\n","  classification_report_result=classification_report(y_test,test_pred)\n","  accuracy_score= metrics.accuracy_score(y_test,test_pred)* 100 \n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","\n","  return confusion_matrix_result,classification_report_result,accuracy_score\n","\n","\n","# 4.3\n","def Decision_Tree_Classifier(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","           Display Results:\n","                   a. Confusion Matrix\n","                   b. Classification Report\n","                   c. Accuracy\n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = DecisionTreeClassifier(random_state=0)\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  confusion_matrix_result=confusion_matrix(y_test,test_pred)\n","  classification_report_result=classification_report(y_test,test_pred)\n","  accuracy_score= metrics.accuracy_score(y_test,test_pred)* 100 \n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","\n","  return confusion_matrix_result,classification_report_result,accuracy_score\n","  \n","# 4.4  \n","def RandomForest_Classifier(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","           Display Results:\n","                   a. Confusion Matrix\n","                   b. Classification Report\n","                   c. Accuracy\n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = RandomForestClassifier( random_state=0)\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  confusion_matrix_result=confusion_matrix(y_test,test_pred)\n","  classification_report_result=classification_report(y_test,test_pred)\n","  accuracy_score= metrics.accuracy_score(y_test,test_pred)* 100 \n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","\n","  return confusion_matrix_result,classification_report_result,accuracy_score\n","\n","# 4.5\n","def XGB_Classifier(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","           Display Results:\n","                   a. Confusion Matrix\n","                   b. Classification Report\n","                   c. Accuracy\n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = XGBClassifier()\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test.values)\n","  confusion_matrix_result=confusion_matrix(y_test,test_pred)\n","  classification_report_result=classification_report(y_test,test_pred)\n","  accuracy_score= metrics.accuracy_score(y_test,test_pred)* 100 \n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","\n","  return confusion_matrix_result,classification_report_result,accuracy_score\n","\n","\n","#5. REGRESSION MODELLING\n","\n","# 5.1\n","def Linear_Regression(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","            Returns root mean squared error value for model evaluation  \n","                  \n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = LinearRegression()\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  rmse_score=math.sqrt(mean_squared_error(y_test,test_pred))\n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","  return rmse_score\n","\n","# 5.2\n","def Support_Vector_Regressor(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","            Returns root mean squared error value for model evaluation  \n","                  \n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = SVR()\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  rmse_score=math.sqrt(mean_squared_error(y_test,test_pred))\n","\n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","  return rmse_score\n","\n","# 5.3\n","def Decision_Tree_Regressor(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","            Returns root mean squared error value for model evaluation  \n","                  \n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = DecisionTreeRegressor(random_state=0)\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  rmse_score=math.sqrt(mean_squared_error(y_test,test_pred))\n","\n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","  return rmse_score \n","\n","# 5.4\n","def RandomForest_Regressor(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","            Returns root mean squared error value for model evaluation  \n","                  \n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = RandomForestRegressor( random_state=0)\n","  model=model.fit(X_train,y_train)\n","  test_pred=model.predict(X_test)\n","  rmse_score=math.sqrt(mean_squared_error(y_test,test_pred))\n","\n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","  return rmse_score\n","\n","#5.5\n","def XGB_Regressor(df,target_variable,output_file_name):\n","  ''' \n","    Create and train machine learning model for prediction of independent variable\n","    based on dependent variables in the dataframe. \n","    Input Parameters: \n","                    a. DataFrame\n","                    b. Target Variable: 'target_variable'\n","                    c. Output File Name: 'output_file_name' or None (If don't want to save)\n","                    \n","    Returns: \n","            Returns root mean squared error value for model evaluation  \n","                  \n","  '''\n","  X_train, X_test, y_train, y_test=train_and_test_split(df,target_variable)\n","  model = xg.XGBRegressor(objective ='reg:linear')\n","  model=model.fit(X_train.values,y_train.values)\n","  test_pred=model.predict(X_test.values)\n","  rmse_score=math.sqrt(mean_squared_error(y_test,test_pred))\n","\n","  if output_file_name != None:\n","    pickle.dump(model, open(output_file_name + '.sav', 'wb'))\n","    print('Model Weights:', output_file_name + '.sav', ', got saved to location:',os.getcwd() + '/' + output_file_name + '.sav')\n","  return rmse_score\n","\n","#6. PREDICTION\n","\n","def predict(model_weights,input_array):\n","  ''' \n","    Prediction of output based on user input provided to model\n","    Input Parameters: \n","                    a. Model Weights: saved model weight file (.sav pickel file )\n","                    b. Input Array: input array ( dependent feature attributes)\n","                       example: [1,2,1,2]\n","                    \n","    Returns: \n","           Returns prediction results  \n","                  \n","  '''\n","  loaded_model = pickle.load(open(model_weights, 'rb'))\n","  predicted=loaded_model.predict([input_array])\n","  return predicted"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbUtdQjtHCLD"},"source":["# df['randNumCol'] = np.random.choice(['male','female'], df.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_3plz-fEN48C"},"source":[""],"execution_count":null,"outputs":[]}]}